#This script runs tests related to Teragen/Terasort, Pig, Hive, Sqoop and Impala.
# Run this script as user "hdfs"


#Assumptions
#Make sure you have jdbc drive installed on the node you are trying to run this script.
#The script is being run on a datanode which has access to hdfs.
#The script also assumes that the datanode is running an impala-daemon to run the impala-scripts.
# Please make sure that mysql is installed and running. If not run the commands below as root.

#if yum list installed | grep "mysql-server"; then
#    echo"MySql-server is already installed."
#else
#    yum install -y mysql-server
#    chkconfig mysqld on
#    service mysqld start
#fi



#########################################################
# Begin Teragen and Terasort testing
#########################################################


hadoop jar /usr/lib/hadoop-0.20-mapreduce/hadoop-examples-2.0.0-mr1-cdh4.4.0.jar teragen 10000 teragen
hadoop jar /usr/lib/hadoop-0.20-mapreduce/hadoop-examples-2.0.0-mr1-cdh4.4.0.jar terasort teragen terasort

#########################################################
#End Teragen and Terasort testing
#########################################################


#########################################################
#Begin Pig Test Case
#########################################################

#Pig test.

cp /etc/passwd .

hadoop dfs -put passwd passwd

cat > pig_test << "EOF"
A = load 'passwd' using PigStorage (':') ;
B = foreach A generate $0 as id;
store B into 'pig_test_output';
EOF

pig -x mapreduce pig_test

#########################################################
#End Pig Test Case
#########################################################

#########################################################
#Begin Hive Test Case
#########################################################
cat > hive_test << "EOF"
create table pokes(foo int, bar string);
create table invites(foo int, bar string) partitioned by (ds string);
show tables;
EOF

hive -f hive_test


#########################################################
#End of the Hive Test Case
#########################################################

#########################################################
#Begin Sqoop Test Case
#########################################################

su hdfs
cd
cat > mysql_test << "EOF"
create database if not exists test;
use test;
create table users(foo int, bar text);
show tables;
insert into users (foo,bar) values (1,"something"),(2,"test"),(3,"data");
EOF

sqoop import --connect jdbc:mysql://localhost/test -table users -m 1


#########################################################
#End of the Sqoop Test Case
#########################################################

#########################################################
#Begin the Impala Test Case
#########################################################

hdfs dfs -mkdir -p /user/impala
hdfs dfs -chown impala:impala /user/impala

hdfs dfs -mkdir -p /user/impala/sample_data/tab1 /user/impala/sample_data/tab2 /user/impala/sample_data/tab3


cat > tab1.csv << "EOF"
1,true,123.123,2012-10-24 08:55:00
2,false,1243.5,2012-10-25 13:40:00
3,false,24453.325,2008-08-22 09:33:21.123
4,false,243423.325,2007-05-12 22:32:21.33454
5,true,243.325,1953-04-22 09:11:33
EOF

cat > tab2.csv << "EOF"
1,true,12789.123
2,false,1243.5
3,false,24453.325
4,false,2423.3254
5,true,243.325
60,false,243565423.325
70,true,243.325
80,false,243423.325
90,true,243.325
EOF

hdfs dfs -put tab1.csv /user/impala/sample_data/tab1
hdfs dfs -put tab2.csv /user/impala/sample_data/tab2


cat > customer_setup.sql << EOF
DROP TABLE IF EXISTS tab1;
-- The EXTERNAL clause means the data is located outside the central location for Impala data files
-- and is preserved when the associated Impala table is dropped. We expect the data to already
-- exist in the directory specified by the LOCATION clause.
CREATE EXTERNAL TABLE tab1
(
id INT,
col_1 BOOLEAN,
col_2 DOUBLE,
col_3 TIMESTAMP
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
LOCATION '/user/impala/sample_data/tab1';

DROP TABLE IF EXISTS tab2;
-- TAB1 is an external table, similar to TAB1.
CREATE EXTERNAL TABLE tab2
(
id INT,
col_1 BOOLEAN,
col_2 DOUBLE
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
LOCATION '/user/impala/sample_data/tab2';
-- Create a new customer_setup.sql with the following content.
--
-- store_sales fact table and surrounding dimension tables only
--
create database tpcds;
use tpcds;

drop table if exists customer;
create external table customer
(
c_customer_sk int,
c_customer_id string,
c_current_cdemo_sk int,
c_current_hdemo_sk int,
c_current_addr_sk int,
c_first_shipto_date_sk int,
c_first_sales_date_sk int,
c_salutation string,
c_first_name string,
c_last_name string,
c_preferred_cust_flag string,
c_birth_day int,
c_birth_month int,
c_birth_year int,
c_birth_country string,
c_login string,
c_email_address string,
c_last_review_date string
)
row format delimited fields terminated by '|'
location '/user/hive/warehouse/tpcds/customer';

drop table if exists customer_address;
create external table customer_address
(
ca_address_sk int,
ca_address_id string,
ca_street_number string,
ca_street_name string,
ca_street_type string,
ca_suite_number string,
ca_city string,
ca_county string,
ca_state string,
ca_zip string,
ca_country string,
ca_gmt_offset float,
ca_location_type string
)
row format delimited fields terminated by '|'
location '/user/hive/warehouse/tpcds/customer_address';
EOF

impala-shell -f customer_setup.sql


#########################################################
#End of the Impala Test Case
#########################################################


#########################################################
#Solr Testing due in the next phase.
#########################################################

